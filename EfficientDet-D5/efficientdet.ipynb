{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODELS_DIR = os.path.join(\"/content\", \"pretrained\")\n",
    "EFFICIENTDET_PYTORCH_DIR = os.path.join(\"/content\", \"efficientdet-pytorch\")\n",
    "EFFICIENTDET_PYTORCH_GIT_LINK = \"https://github.com/rwightman/efficientdet-pytorch.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, subprocess\n",
    "if not all(x in sys.path for x in [os.path.abspath(os.pardir), EFFICIENTDET_PYTORCH_DIR]):\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "    sys.path.insert(0, EFFICIENTDET_PYTORCH_DIR)\n",
    "import CONFIG\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_efficientdet():\n",
    "    if not all([os.path.exists(PRETRAINED_MODELS_DIR), os.path.exists(EFFICIENTDET_PYTORCH_DIR)]):\n",
    "        os.makedirs(PRETRAINED_MODELS_DIR, exist_ok=True)\n",
    "        subprocess.call(f\"git clone {EFFICIENTDET_PYTORCH_GIT_LINK}\", shell=True, cwd=CONFIG.CFG.BASEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_efficientdet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import gc\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CONFIG.CFG.DATA.BASE\n",
    "MODELS_OUT_DIR = CONFIG.CFG.DATA.MODELS_OUT\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "ON_CPU = DEVICE == torch.device('cpu')\n",
    "TRAIN_BATCH_SIZE = 4 if ON_CPU else 5\n",
    "VALID_BATCH_SIZE = 4 if ON_CPU else 6\n",
    "NUM_EPOCHS = 5 if ON_CPU else 10\n",
    "LEARNING_RATE = 4e-5\n",
    "NEW_COLUMNS = ['x', 'y', 'w', 'h']\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "\n",
    "UNIQ_TRAIN_IMAGE_IDS = train_df[\"image_id\"].unique()\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the bboxes into new columns\n",
    "sep_bboxes = np.stack(train_df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "for i, new_column in enumerate(NEW_COLUMNS):\n",
    "    train_df[new_column] = sep_bboxes[:, i]\n",
    "train_df.drop(columns=['bbox'], inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.loc[:, \"fold\"] = -1\n",
    "kf = KFold(shuffle=True, random_state=42)\n",
    "for fold, (train_ids, valid_ids) in enumerate(kf.split(UNIQ_TRAIN_IMAGE_IDS)):\n",
    "    ids_valid = [UNIQ_TRAIN_IMAGE_IDS[k] for k in valid_ids]\n",
    "\n",
    "    indices = train_df[train_df['image_id'].isin(ids_valid)].index\n",
    "    train_df.loc[indices, \"fold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    assert image is not None, f\"IMAGE NOT FOUND AT {image_path}\"\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.RandomSizedCrop(min_max_height=(800, 800), height=1024, width=1024, p=0.5),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "            ],p=0.9),\n",
    "            A.ToGray(p=0.01),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1),\n",
    "            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WheatDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_ids = df['image_id'].unique()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = load_image(os.path.join(self.image_dir, f\"{image_id}.jpg\")).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        records = self.df[self.df['image_id'] == image_id]\n",
    "\n",
    "        boxes = records[NEW_COLUMNS].values\n",
    "        area = boxes[:, 2] * boxes[:, 3]\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "        # change the co-ordinates into expected [x, y, x+w, y+h] format\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        # since all the boxes are wheat, it's all 1s\n",
    "        labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        target[\"area\"] = area\n",
    "\n",
    "        if self.transforms:\n",
    "            aug = self.transforms(image=image, bboxes=boxes, labels=labels)\n",
    "            while len(aug['bboxes']) == 0:\n",
    "                aug = self.transforms(image=image, bboxes=boxes, labels=labels)\n",
    "            image = aug['image']\n",
    "            target['boxes'] = torch.as_tensor(aug['bboxes'], dtype=torch.float32)\n",
    "\n",
    "            # format yxyx\n",
    "            target['boxes'][:, [0,1,2,3]] = target['boxes'][:, [1,0,3,2]]\n",
    "            target['labels'] = torch.stack(aug['labels'])\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "train_dataset = WheatDataset(\n",
    "    train_df[train_df['fold'] != fold],\n",
    "    os.path.join(DATA_DIR, \"train\"),\n",
    "    transforms=get_train_transforms(),\n",
    ")\n",
    "\n",
    "validation_dataset = WheatDataset(\n",
    "    train_df[train_df['fold'] == fold],\n",
    "    os.path.join(DATA_DIR, \"train\"),\n",
    "    transforms=get_valid_transforms(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        sampler=RandomSampler(train_dataset),\n",
    "        num_workers=1,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    sampler=SequentialSampler(validation_dataset),\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "def get_model():\n",
    "    model_config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    model = EfficientDet(model_config, pretrained_backbone=False)\n",
    "    checkpoint = torch.load(os.path.join(PRETRAINED_MODELS_DIR, 'tf_efficientdet_d5-ef44aea8.pth'))\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model_config.num_classes = 1\n",
    "    model_config.image_size = IMAGE_SIZE\n",
    "    model.class_net = HeadNet(model_config, num_outputs=model_config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "    return DetBenchTrain(model, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model = get_model()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_data_loader, lr_scheduler):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    for b_idx, (images, targets) in enumerate(train_data_loader):\n",
    "        images = torch.stack(images).to(DEVICE).float()\n",
    "\n",
    "        target = {\n",
    "            'bbox': [],\n",
    "            'cls': []\n",
    "        }\n",
    "\n",
    "        for d in targets:\n",
    "            target['bbox'].append(d['boxes'].to(DEVICE).float())\n",
    "            target['cls'].append(d['labels'].to(DEVICE).float())\n",
    "\n",
    "        output = model(images, target)\n",
    "        loss = output['loss']\n",
    "\n",
    "        losses.update(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if b_idx % 50 == 0:\n",
    "            print(f\"Epoch: {epoch} Batch Index: {b_idx} Loss: {loss.item()} LR: {optimizer.param_groups[0]['lr']}\")\n",
    "    if lr_scheduler is not None:\n",
    "            lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, valid_data_loader):\n",
    "    losses = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for _, (images, targets) in enumerate(valid_data_loader):\n",
    "            # move the images and targets to device\n",
    "            images = torch.stack(images).to(DEVICE).float()\n",
    "            target = {\n",
    "                'bbox': [],\n",
    "                'cls': []\n",
    "            }\n",
    "\n",
    "            for d in targets:\n",
    "                target['bbox'].append(d['boxes'].to(DEVICE).float())\n",
    "                target['cls'].append(d['labels'].to(DEVICE).float())\n",
    "\n",
    "            output = model(images, target)\n",
    "            val_loss = output['loss']\n",
    "\n",
    "            losses.update(val_loss.item())\n",
    "    print(f\"Validation Loss: {losses.avg}\\n\")\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    best_val = float('inf')\n",
    "    train_epoch(model, optimizer, train_data_loader, lr_scheduler)\n",
    "    val_loss = validate_epoch(model, valid_data_loader)  \n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        print(\"SAVING MODEL\")\n",
    "        torch.save(model.state_dict(), os.path.join(MODELS_OUT_DIR, f\"best_model.pth\"))\n",
    "    print(f\"End of epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.save(model.model.state_dict(), \"test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.upload_to_kaggle(\"efficientdetd5\", \"Efficient Det D5\", new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFERENCE\n",
    "class WheatTestDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = dataframe['image_id'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        return image, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_transforms():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WheatTestDataset(test_df, os.path.join(DATA_DIR, \"test\"), get_test_transforms())\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
    "\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "def load_test_model(ck_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    test_model = EfficientDet(config, pretrained_backbone=False)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 512\n",
    "    test_model.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=0.001, momentum=0.01))\n",
    "\n",
    "    checkpoint = torch.load(ck_path)\n",
    "    test_model.load_state_dict(checkpoint)\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    test_model = DetBenchPredict(test_model, config)\n",
    "    test_model.eval()\n",
    "    return test_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = load_test_model(\"test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detection_threshold = 0.5\n",
    "results = []\n",
    "\n",
    "for images, image_ids in test_data_loader:\n",
    "    images = torch.stack(images).to(DEVICE).float()\n",
    "    with torch.no_grad():\n",
    "        outputs = test_model(images, torch.tensor([1]*images.shape[0]).to(DEVICE).float(), torch.tensor([[512, 512]]*images.shape[0]).to(DEVICE).float())\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "\n",
    "            boxes = outputs[i]['boxes'].data.cpu().numpy()\n",
    "            scores = outputs[i]['scores'].data.cpu().numpy()\n",
    "            \n",
    "            boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "            scores = scores[scores >= detection_threshold]\n",
    "            image_id = image_ids[i]\n",
    "            \n",
    "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "            \n",
    "            result = {\n",
    "                'image_id': image_id,\n",
    "                'PredictionString': format_prediction_string(boxes, scores)\n",
    "            }\n",
    "\n",
    "            \n",
    "            results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}