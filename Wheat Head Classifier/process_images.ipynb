{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(1, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from glob import glob\n",
    "import re\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = CONFIG.CFG.DATA.BASE\n",
    "IMAGES_OUT = CONFIG.CFG.DATA.BASE + \"/new_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(INPUT_DIR, \"train.csv\"))\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image_pil, width, height):\n",
    "    '''\n",
    "    Resize PIL image keeping ratio and using white background.\n",
    "    '''\n",
    "    ratio_w = width / image_pil.width\n",
    "    ratio_h = height / image_pil.height\n",
    "    if ratio_w < ratio_h:\n",
    "        # It must be fixed by width\n",
    "        resize_width = width\n",
    "        resize_height = round(ratio_w * image_pil.height)\n",
    "    else:\n",
    "        # Fixed by height\n",
    "        resize_width = round(ratio_h * image_pil.width)\n",
    "        resize_height = height\n",
    "    image_resize = image_pil.resize((resize_width, resize_height), Image.ANTIALIAS)\n",
    "    background = Image.new('RGBA', (width, height), (255, 255, 255, 255))\n",
    "    offset = (round((width - resize_width) / 2), round((height - resize_height) / 2))\n",
    "    background.paste(image_resize, offset)\n",
    "    return background.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bbox(bbox_str):\n",
    "    replace_brac = re.sub(\"\\[|\\]\", \"\", bbox_str)\n",
    "    bbox_list = np.array([int(val[:-2]) for val in replace_brac.split(\",\") if val != ''])\n",
    "    return bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_OUT):\n",
    "    os.makedirs(IMAGES_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, row in train_df.iterrows():\n",
    "    try:\n",
    "        bbox = parse_bbox(row.bbox)\n",
    "        img = Image.open(os.path.join(INPUT_DIR, \"train\", f\"{row.image_id}.jpg\"))\n",
    "        cropped_img = img.crop((bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]))\n",
    "        final_img = resize_with_pad(cropped_img, 250, 250)\n",
    "        final_img.save(os.path.join(IMAGES_OUT, f\"{row.image_id}_{i}.jpg\"))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{len(glob(IMAGES_OUT+'/*.jpg'))} images generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uniq_imgs = train_df.image_id.unique()\n",
    "for sample_img in uniq_imgs:\n",
    "    img = cv2.imread(os.path.join(INPUT_DIR, \"train\", f\"{sample_img}.jpg\"), -1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    bboxes = train_df[train_df.image_id == sample_img].bbox\n",
    "    for box in bboxes:\n",
    "        try:\n",
    "            bbox = parse_bbox(box)\n",
    "            cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[0]+bbox[2], bbox[1]+bbox[3]), (255,255,255), -1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    for i in range(len(bboxes)):\n",
    "        random_sample = (np.random.randint(1024-100), np.random.randint(1024-100))\n",
    "        img1 = img[random_sample[1]:random_sample[1]+150, random_sample[0]:random_sample[0]+150]\n",
    "        img2 = Image.fromarray(img1)\n",
    "        final_img = resize_with_pad(img2, 250, 250)\n",
    "        final_img.save(os.path.join(IMAGES_OUT, f\"{sample_img}-{i}.jpg\"))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}