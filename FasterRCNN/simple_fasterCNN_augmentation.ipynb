{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(1, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, re\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CONFIG.CFG.DATA.BASE\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_COLUMNS = ['x', 'y', 'w', 'h']\n",
    "\n",
    "# initialize new columns with -1\n",
    "for new_column in NEW_COLUMNS:\n",
    "    train_df[new_column] = -1\n",
    "\n",
    "# expand the bbox coordinates into x, y, w, h\n",
    "def expand_bbox(x):\n",
    "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x), dtype=np.float)\n",
    "    if len(r) == 0:\n",
    "        r = [-1, -1, -1, -1]\n",
    "    return r\n",
    "\n",
    "train_df[NEW_COLUMNS] = np.stack(train_df['bbox'].apply(lambda x: expand_bbox(x)))\n",
    "train_df.drop(columns=['bbox'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    assert image is not None, f\"IMAGE NOT FOUND! AT {image_path}\"\n",
    "    return image\n",
    "\n",
    "def load_image_from_folder(image_id, folder=\"train\"):\n",
    "    path = os.path.join(INPUT_DIR, folder, f\"{image_id}.jpg\")\n",
    "    return load_image(path)\n",
    "\n",
    "def read_image_from_path(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def read_image_from_train_folder(image_id):\n",
    "    path = os.path.join(INPUT_DIR, \"train\", f\"{image_id}.jpg\")\n",
    "    return read_image_from_path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_id = \"b6ab77fd7\"\n",
    "plt.imshow(read_image_from_train_folder(sample_image_id))\n",
    "_ = plt.title(sample_image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes_on_image(boxes, image, color=(255,0,0)):\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, 3\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_id = train_df.image_id.sample().item()\n",
    "sample_image = read_image_from_train_folder(sample_image_id)\n",
    "sample_bounding_boxes = train_df[train_df.image_id == sample_image_id][[\"x\", \"y\", \"x2\", \"y2\"]]\n",
    "\n",
    "plt.imshow(draw_boxes_on_image(sample_bounding_boxes.to_numpy(), sample_image, color=(0, 200, 200)))\n",
    "plt.title(sample_image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_channels=in_features, num_classes=2)\n",
    "\n",
    "model.roi_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def move_batch_to_device(images, targets):\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    return images, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_image_ids = train_df[\"image_id\"].unique()\n",
    "\n",
    "n_validation = int(0.2* len(unique_image_ids))\n",
    "valid_ids = unique_image_ids[-n_validation:]\n",
    "train_ids = unique_image_ids[:-n_validation]\n",
    "\n",
    "validation_df = train_df[train_df['image_id'].isin(valid_ids)]\n",
    "trainining_df = train_df[train_df['image_id'].isin(train_ids)]\n",
    "\n",
    "print(\"%i training samples\\n%i validation samples\" % (len(trainining_df.image_id.unique()), len(validation_df.image_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WheatDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = dataframe['image_id'].unique()\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = read_image_from_train_folder(image_id).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        # change the shape from [h,w,c] to [c,h,w]  \n",
    "        image = torch.from_numpy(image).permute(2,0,1)\n",
    "\n",
    "        records = self.df[self.df['image_id'] == image_id]\n",
    "\n",
    "        boxes = records[['x', 'y', 'x2', 'y2']].values\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "\n",
    "        n_boxes = boxes.shape[0]\n",
    "\n",
    "        labels = torch.ones((n_boxes,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WheatDataset(trainining_df)\n",
    "valid_dataset = WheatDataset(validation_df)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "is_training_on_cpu = device == torch.device('cpu')\n",
    "batch_size = 4 if is_training_on_cpu else 16\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_of_images, batch_of_targets = next(iter(train_data_loader))\n",
    "\n",
    "sample_boxes = batch_of_targets[0]['boxes'].cpu().numpy().astype(np.int32)\n",
    "# convert to normal image format\n",
    "sample_image = batch_of_images[0].permute(1,2,0).cpu().numpy()\n",
    "\n",
    "plt.imshow(draw_boxes_on_image(sample_boxes, sample_image, color=(0,200,200)))\n",
    "\n",
    "\n",
    "# %%\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.007, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "\n",
    "# %%\n",
    "num_epochs = 1 if is_training_on_cpu else 5\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    average_loss = 0\n",
    "    for batch_id, (images, targets) in enumerate(train_data_loader):\n",
    "        images, targets = move_batch_to_device(images, targets)\n",
    "\n",
    "        loss_dict = model(images,targets)\n",
    "        batch_loss = sum(loss for loss in loss_dict.values()) / len(loss_dict)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        loss_value = batch_loss.item()\n",
    "        average_loss = average_loss + (loss_value - average_loss) / (batch_id + 1)\n",
    "\n",
    "        print(\"Mini-batch: %i/%i Loss: %.4f\" % ( batch_id + 1, len(train_data_loader), average_loss), end='\\r')\n",
    "        if batch_id % 100 == 0:\n",
    "            print(\"Mini-batch: %i/%i Loss: %.4f\" % ( batch_id + 1, len(train_data_loader), average_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "def make_validation_iter():\n",
    "    valid_data_iter = iter(valid_data_loader)\n",
    "    for images, targets in valid_data_iter:\n",
    "        images, targets = move_batch_to_device(images, targets)\n",
    "\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "        outputs = model(images)\n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        for image, output, target in zip(images, outputs, targets):\n",
    "            predicted_boxes = output['boxes'].cpu().detach().numpy().astype(np.int32)\n",
    "            ground_truth_boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
    "            image = image.permute(1,2,0).cpu().numpy()\n",
    "            yield image, ground_truth_boxes, predicted_boxes\n",
    "\n",
    "validation_iter = make_validation_iter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image, ground_truth_boxes, predicted_boxes = next(validation_iter)\n",
    "image = draw_boxes_on_image(predicted_boxes, image, (255,0,0))\n",
    "image = draw_boxes_on_image(ground_truth_boxes, image , (0,255,0))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(CONFIG.CFG.DATA.OUT_MODELS, 'simple_fastercnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG.upload_to_kaggle(\"wheatfastercnn\", \"Simple Faster R-CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}